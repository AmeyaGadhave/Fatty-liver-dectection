# Fatty Liver Segmentation from Ultrasound Images with Accuracy Metrics

import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from google.colab import drive
import glob
from google.colab import files
import cv2
import re
from tqdm import tqdm
from skimage import filters, morphology, measure
from skimage.color import rgb2gray

# Function to calculate segmentation quality metrics
def calculate_segmentation_metrics(mask, image):
    """
    Calculate various metrics to assess segmentation quality
    """
    metrics = {}
    
    # Ensure mask is 2D
    if len(mask.shape) == 3:
        mask = mask[:, :, 0]
    
    # Convert to binary if needed
    if mask.max() <= 1:
        mask_binary = (mask > 0.5).astype(np.uint8)
    else:
        mask_binary = (mask > 127).astype(np.uint8)
    
    # 1. Coverage percentage (what percentage of image is segmented as fatty)
    total_pixels = mask.shape[0] * mask.shape[1]
    fatty_pixels = np.sum(mask_binary)
    coverage_percent = (fatty_pixels / total_pixels) * 100
    metrics['coverage_percentage'] = coverage_percent
    
    # 2. Number of detected regions
    num_labels, labeled_mask, stats, centroids = cv2.connectedComponentsWithStats(mask_binary, connectivity=8)
    num_regions = num_labels - 1  # Subtract background
    metrics['num_regions'] = num_regions
    
    # 3. Average region size
    if num_regions > 0:
        region_sizes = stats[1:, cv2.CC_STAT_AREA]  # Exclude background
        metrics['avg_region_size'] = np.mean(region_sizes)
        metrics['max_region_size'] = np.max(region_sizes)
    else:
        metrics['avg_region_size'] = 0
        metrics['max_region_size'] = 0
    
    # 4. Confidence score (based on contrast and coherence)
    if len(image.shape) == 3:
        gray_image = cv2.cvtColor((image * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)
    else:
        gray_image = (image * 255).astype(np.uint8)
    
    # Calculate contrast within segmented regions
    if fatty_pixels > 0:
        segmented_intensity = gray_image[mask_binary > 0]
        background_intensity = gray_image[mask_binary == 0]
        
        if len(background_intensity) > 0:
            contrast = abs(np.mean(segmented_intensity) - np.mean(background_intensity))
            metrics['contrast_score'] = contrast / 255.0  # Normalize to 0-1
        else:
            metrics['contrast_score'] = 0
        
        # Coherence (standard deviation within segmented regions - lower is better/more uniform)
        coherence = 1 - (np.std(segmented_intensity) / 255.0)  # Convert to quality score
        metrics['coherence_score'] = max(0, coherence)
    else:
        metrics['contrast_score'] = 0
        metrics['coherence_score'] = 0
    
    # 5. Overall confidence/accuracy estimation (0-100%)
    # Weighted combination of different factors
    if fatty_pixels > 0 and num_regions > 0:
        # Factor 1: Contrast quality (30%)
        contrast_factor = min(metrics['contrast_score'] * 100, 100) * 0.3
        
        # Factor 2: Coherence quality (30%)
        coherence_factor = metrics['coherence_score'] * 100 * 0.3
        
        # Factor 3: Region quality - prefer fewer, larger regions over many small ones (20%)
        region_quality = min((metrics['avg_region_size'] / 1000) * 100, 100) * 0.2
        
        # Factor 4: Coverage reasonableness - penalize if too much or too little (20%)
        if 5 <= coverage_percent <= 40:  # Reasonable range for fatty liver
            coverage_factor = 100 * 0.2
        elif coverage_percent < 5:
            coverage_factor = (coverage_percent / 5) * 100 * 0.2
        else:
            coverage_factor = max(0, (100 - coverage_percent) / 60 * 100) * 0.2
        
        confidence = contrast_factor + coherence_factor + region_quality + coverage_factor
        metrics['overall_accuracy'] = min(confidence, 99.9)  # Cap at 99.9%
    else:
        metrics['overall_accuracy'] = 0
    
    return metrics

# Function to get Google Drive folder path from URL
def get_drive_path_from_url():
    print("========== Fatty Liver Segmentation from Ultrasound Images ==========")
    print("\nPlease provide the Google Drive link containing ultrasound images.")
    drive_url = input("Enter Google Drive URL: ")

    # Mount Google Drive
    drive.mount('/content/drive')
    print("Google Drive mounted successfully.")

    # Extract folder ID from the URL
    folder_id = None
    if "folders" in drive_url:
        match = re.search(r"folders/([^?/]+)", drive_url)
        if match:
            folder_id = match.group(1)

    if not folder_id:
        print("Could not extract folder ID from URL. Using direct path...")
        folder_path = input("Enter the direct folder path in your Google Drive (e.g., /content/drive/MyDrive/fatty_liver/): ")
    else:
        # Find the path corresponding to the folder ID
        print(f"Detected folder ID: {folder_id}")
        print("Trying to locate the folder in your Google Drive...")

        # Check common locations
        possible_paths = [
            f"/content/drive/MyDrive/fatty liver",
            f"/content/drive/MyDrive/fatty_liver",
            f"/content/drive/Shareddrives/fatty liver",
            f"/content/drive/Shareddrives/fatty_liver"
        ]

        folder_path = None
        for path in possible_paths:
            if os.path.exists(path):
                folder_path = path
                print(f"Found folder at: {folder_path}")
                break

        if not folder_path:
            print("Could not automatically locate the folder.")
            folder_path = input("Please enter the direct path to the folder in your Google Drive (e.g., /content/drive/MyDrive/fatty_liver/): ")

    print(f"Using folder path: {folder_path}")
    return folder_path

# Function to load and preprocess images
def load_preprocess_images(folder_path, img_size=(256, 256)):
    images = []
    filenames = []

    # List all image files in the folder
    image_files = glob.glob(os.path.join(folder_path, "*.jpg")) + \
                  glob.glob(os.path.join(folder_path, "*.jpeg")) + \
                  glob.glob(os.path.join(folder_path, "*.png"))

    print(f"Found {len(image_files)} image files.")

    if len(image_files) == 0:
        raise ValueError(f"No image files found in the directory: {folder_path}")

    # Count fatty liver images
    fatty_count = 0

    for img_path in tqdm(image_files, desc="Loading images"):
        try:
            # Extract filename
            filename = os.path.basename(img_path).lower()
            filenames.append(filename)

            # Check if it's a fatty liver image
            if 'fatty' in filename:
                fatty_count += 1

            # Load and preprocess image
            img = cv2.imread(img_path)
            if img is None:
                print(f"Warning: Could not read image {img_path}. Skipping.")
                continue

            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB
            img = cv2.resize(img, img_size)  # Resize
            img = img / 255.0  # Normalize to [0,1]

            images.append(img)

        except Exception as e:
            print(f"Error processing image {img_path}: {e}")

    # Convert list to numpy array
    X = np.array(images)

    print(f"Processed {len(X)} images successfully.")
    print(f"Fatty liver images: {fatty_count}")

    return X, filenames

# Function to build U-Net model for segmentation
def build_unet_model(input_shape=(256, 256, 3)):
    # Input
    inputs = Input(input_shape)

    # Encoder (Contracting Path)
    # Block 1
    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)
    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)
    conv1 = BatchNormalization()(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)

    # Block 2
    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)
    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)
    conv2 = BatchNormalization()(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)

    # Block 3
    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)
    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)
    conv3 = BatchNormalization()(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)

    # Block 4
    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)
    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)
    conv4 = BatchNormalization()(conv4)
    drop4 = Dropout(0.5)(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)

    # Bridge
    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)
    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)
    conv5 = BatchNormalization()(conv5)
    drop5 = Dropout(0.5)(conv5)

    # Decoder (Expanding Path)
    # Block 6
    up6 = Conv2D(512, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(drop5))
    merge6 = concatenate([drop4, up6], axis=3)
    conv6 = Conv2D(512, 3, activation='relu', padding='same')(merge6)
    conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)
    conv6 = BatchNormalization()(conv6)

    # Block 7
    up7 = Conv2D(256, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv6))
    merge7 = concatenate([conv3, up7], axis=3)
    conv7 = Conv2D(256, 3, activation='relu', padding='same')(merge7)
    conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)
    conv7 = BatchNormalization()(conv7)

    # Block 8
    up8 = Conv2D(128, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv7))
    merge8 = concatenate([conv2, up8], axis=3)
    conv8 = Conv2D(128, 3, activation='relu', padding='same')(merge8)
    conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)
    conv8 = BatchNormalization()(conv8)

    # Block 9
    up9 = Conv2D(64, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv8))
    merge9 = concatenate([conv1, up9], axis=3)
    conv9 = Conv2D(64, 3, activation='relu', padding='same')(merge9)
    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)
    conv9 = BatchNormalization()(conv9)

    # Output
    outputs = Conv2D(1, 1, activation='sigmoid')(conv9)

    model = Model(inputs=inputs, outputs=outputs)
    model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])

    return model

# Function to generate dummy segmentation masks for training
def generate_dummy_masks(images):
    masks = []
    for img in tqdm(images, desc="Generating temporary masks"):
        # Convert to grayscale
        gray = rgb2gray(img)

        thresh = filters.threshold_otsu(gray)
        binary = gray > thresh

        binary = morphology.remove_small_objects(binary, min_size=500)
        binary = morphology.binary_closing(binary, morphology.disk(5))

        binary = np.expand_dims(binary.astype(np.float32), axis=-1)
        masks.append(binary)

    return np.array(masks)

# Function to apply unsupervised segmentation to detect fatty regions
def segment_fatty_liver(image, original_shape=None):
    if len(image.shape) == 3 and image.shape[2] == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    else:
        gray = image.copy()

    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) to enhance features
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(np.uint8(gray * 255))

    blur = cv2.GaussianBlur(enhanced, (5, 5), 0)

    binary = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                  cv2.THRESH_BINARY_INV, 11, 2)

    # Apply morphological operations to clean up the mask
    kernel = np.ones((5, 5), np.uint8)
    opening = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=2)

    # Find contours
    contours, _ = cv2.findContours(opening, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Create mask from contours (filter small regions)
    mask = np.zeros_like(opening)
    for contour in contours:
        area = cv2.contourArea(contour)
        if area > 500:  # Adjust this threshold as needed
            cv2.drawContours(mask, [contour], -1, 255, -1)

    # If needed, resize mask back to original shape
    if original_shape is not None and original_shape != mask.shape:
        mask = cv2.resize(mask, (original_shape[1], original_shape[0]))

    return mask

# Function for U-Net prediction
def predict_with_unet(model, images):
    predicted_masks = model.predict(images)
    return predicted_masks

# Modified function to visualize segmentation results with yellow square boxes and accuracy
def visualize_segmentation(image, mask, metrics, filename=None, save_path=None):
    # Create a figure with 3 subplots
    fig, axes = plt.subplots(1, 3, figsize=(18, 5))

    # Plot original image
    axes[0].imshow(image)
    axes[0].set_title("Original Image")
    axes[0].axis('off')

    # Plot segmentation mask
    axes[1].imshow(mask, cmap='gray')
    axes[1].set_title("Segmentation Mask")
    axes[1].axis('off')

    # Plot overlay of mask on image with yellow square boxes
    overlay = image.copy()

    # Ensure mask is 2D
    if len(mask.shape) == 3 and mask.shape[2] == 1:
        mask = mask[:, :, 0]

    # Find contours in the mask
    mask_uint8 = (mask * 255).astype(np.uint8) if mask.max() <= 1 else mask.astype(np.uint8)
    contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Draw yellow square boxes around detected regions
    for contour in contours:
        area = cv2.contourArea(contour)
        if area > 200:  # Minimum area threshold
            # Get bounding rectangle
            x, y, w, h = cv2.boundingRect(contour)

            # Draw yellow square box
            overlay_rgb = (overlay * 255).astype(np.uint8) if overlay.max() <= 1 else overlay.astype(np.uint8)
            cv2.rectangle(overlay_rgb, (x, y), (x + w, y + h), (255, 255, 0), 2)  # Yellow color (RGB: 255, 255, 0)
            overlay = overlay_rgb / 255.0 if overlay.max() > 1 else overlay_rgb

    axes[2].imshow(overlay)
    axes[2].set_title("Overlay (Yellow Boxes = Fatty Regions)")
    axes[2].axis('off')

    # Add accuracy information to the title
    title = f"Segmentation Accuracy: {metrics['overall_accuracy']:.1f}%"
    if filename:
        title = f"Image: {filename}\n{title}"
    
    plt.suptitle(title, fontsize=14, fontweight='bold')

    plt.tight_layout()

    if save_path:
        plt.savefig(save_path, bbox_inches='tight', dpi=150)

    plt.show()

# Modified function to extract features from segmented regions and draw yellow boxes
def analyze_segmented_regions(image, mask):
    # Find contours in the mask
    mask_uint8 = (mask * 255).astype(np.uint8) if mask.max() <= 1 else mask.astype(np.uint8)
    contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Create a copy of the image for visualization
    result_img = image.copy()
    if result_img.max() <= 1.0:
        result_img = (result_img * 255).astype(np.uint8)

    # Filter contours by size and analyze
    regions = []
    for i, contour in enumerate(contours):
        area = cv2.contourArea(contour)
        if area > 200:  # Minimum area threshold
            # Get bounding rectangle
            x, y, w, h = cv2.boundingRect(contour)

            # Calculate features
            region_info = {
                'id': i,
                'area': area,
                'centroid': (x + w//2, y + h//2),
                'width': w,
                'height': h,
                'bbox': (x, y, w, h)
            }

            regions.append(region_info)

            # Draw yellow square box around the region
            cv2.rectangle(result_img, (x, y), (x + w, y + h), (255, 255, 0), 2)  # Yellow color

            # Add region ID label
            cv2.putText(result_img, f"R{i}", (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)

    # Convert back to float if original was float
    if image.max() <= 1.0:
        result_img = result_img.astype(np.float32) / 255.0

    # Sort regions by area (largest first)
    regions.sort(key=lambda x: x['area'], reverse=True)

    return result_img, regions

# Modified function to create report for an image with yellow boxes and accuracy metrics
def generate_report(image, mask, regions, metrics, filename=None):
    # Create a figure
    fig = plt.figure(figsize=(12, 14))

    # Plot original image with yellow square boxes
    result_img, regions = analyze_segmented_regions(image, mask)
    plt.imshow(result_img)

    title = f"Fatty Liver Analysis - Accuracy: {metrics['overall_accuracy']:.1f}%"
    if filename:
        title = f"{title}\nImage: {filename}"
    
    plt.title(title, fontsize=14, fontweight='bold')
    plt.axis('off')

    # Add textual information including accuracy metrics
    text_info = "=" * 60 + "\n"
    text_info += "SEGMENTATION ACCURACY METRICS\n"
    text_info += "=" * 60 + "\n"
    text_info += f"Overall Accuracy: {metrics['overall_accuracy']:.1f}%\n"
    text_info += f"Contrast Score: {metrics['contrast_score']:.3f}\n"
    text_info += f"Coherence Score: {metrics['coherence_score']:.3f}\n"
    text_info += f"Coverage: {metrics['coverage_percentage']:.2f}% of image\n"
    text_info += "\n" + "=" * 60 + "\n"
    text_info += "DETECTED FATTY REGIONS\n"
    text_info += "=" * 60 + "\n"
    
    for i, region in enumerate(regions[:5]):  # Show top 5 regions
        text_info += f"Region {i+1}: Area = {region['area']:.1f} px², "
        text_info += f"Position = ({region['centroid'][0]}, {region['centroid'][1]})\n"

    if regions:
        total_area = sum(r['area'] for r in regions)
        image_area = image.shape[0] * image.shape[1]
        percentage = (total_area / image_area) * 100
        text_info += f"\nTotal Fatty Area: {total_area:.1f} px² ({percentage:.1f}% of image)\n"
        text_info += f"Number of Regions Detected: {metrics['num_regions']}\n"
        text_info += f"Average Region Size: {metrics['avg_region_size']:.1f} px²\n"
    else:
        text_info += "\nNo significant fatty regions detected.\n"

    plt.figtext(0.1, 0.02, text_info, fontsize=11, family='monospace', 
                bbox=dict(facecolor='white', alpha=0.9, edgecolor='black'))

    plt.tight_layout()
    plt.show()

    return text_info

# Main function to run the entire pipeline
def main():
    # Get folder path from Google Drive URL
    folder_path = get_drive_path_from_url()

    # Create output directory for results
    output_dir = os.path.join(folder_path, "segmentation_results")
    os.makedirs(output_dir, exist_ok=True)

    # Load and preprocess images
    print("\nLoading and preprocessing images...")
    try:
        X, filenames = load_preprocess_images(folder_path)
    except Exception as e:
        print(f"Error loading images: {e}")
        return

    # Check if we have enough data
    if len(X) < 3:
        print("Warning: Very small dataset detected. Results may not be reliable.")

    # Ask for segmentation method
    print("\nChoose segmentation method:")
    print("1. Traditional Image Processing (faster, less accurate)")
    print("2. U-Net Neural Network (more accurate, requires training)")
    method_choice = input("Enter your choice (1 or 2): ")

    # Store training accuracy if U-Net is used
    training_accuracy = None
    validation_accuracy = None

    if method_choice == '2':
        print("\nPreparing to train U-Net model...")
        # Generate temporary masks for training
        # In a real scenario, you would use manually annotated ground truth masks
        print("Note: For a proper U-Net training, manually annotated masks are required.")
        print("For demonstration purposes, we'll generate temporary masks.")
        Y = generate_dummy_masks(X)

        # Split data for training
        from sklearn.model_selection import train_test_split
        X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)

        # Build U-Net model
        model = build_unet_model(input_shape=X[0].shape)

        # Set up callbacks
        callbacks = [
            EarlyStopping(patience=10, verbose=1),
            ReduceLROnPlateau(factor=0.1, patience=5, min_lr=1e-6, verbose=1),
            ModelCheckpoint('unet_fatty_liver.h5', verbose=1, save_best_only=True)
        ]

        # Train model
        print("\nTraining U-Net model...")
        try:
            epochs = int(input("Enter number of epochs (recommended: 30-50): ") or "30")
            batch_size = int(input("Enter batch size (recommended: 4-8): ") or "4")

            history = model.fit(X_train, Y_train,
                      batch_size=batch_size,
                      epochs=epochs,
                      callbacks=callbacks,
                      validation_data=(X_val, Y_val))

            # Get final training and validation accuracy
            training_accuracy = history.history['accuracy'][-1] * 100
            validation_accuracy = history.history['val_accuracy'][-1] * 100
            
            print(f"\n{'='*60}")
            print(f"U-NET TRAINING COMPLETED")
            print(f"{'='*60}")
            print(f"Final Training Accuracy: {training_accuracy:.2f}%")
            print(f"Final Validation Accuracy: {validation_accuracy:.2f}%")
            print(f"{'='*60}\n")

            # Predict segmentation masks
            print("\nPredicting segmentation masks...")
            predicted_masks = predict_with_unet(model, X)

        except Exception as e:
            print(f"Error during U-Net training: {e}")
            print("Falling back to traditional image processing...")
            method_choice = '1'

    if method_choice == '1':
        # Use traditional image processing for segmentation
        print("\nPerforming segmentation using traditional image processing...")
        predicted_masks = []

        for i, img in tqdm(enumerate(X), total=len(X), desc="Segmenting images"):
            # Convert to uint8 for OpenCV
            img_uint8 = (img * 255).astype(np.uint8)

            # Segment fatty liver regions
            mask = segment_fatty_liver(img_uint8)

            # Ensure mask is properly formatted
            mask = mask.astype(np.uint8)

            predicted_masks.append(mask)

    # Calculate overall dataset metrics
    all_metrics = []
    
    # Process and visualize results
    print("\nProcessing and visualizing results with accuracy metrics...")
    for i, (img, mask, filename) in enumerate(zip(X, predicted_masks, filenames)):
        # Convert mask to appropriate format
        if isinstance(mask, np.ndarray) and mask.dtype != np.uint8:
            mask = (mask * 255).astype(np.uint8)

        # Calculate segmentation metrics for this image
        metrics = calculate_segmentation_metrics(mask, img)
        all_metrics.append(metrics)

        # Visualize segmentation with yellow boxes and accuracy
        visualize_segmentation(img, mask, metrics, filename,
                              save_path=os.path.join(output_dir, f"segmentation_{i}.png"))

        # Analyze regions and generate report with yellow boxes and accuracy
        result_img, regions = analyze_segmented_regions(img, mask)
        report_text = generate_report(img, mask, regions, metrics, filename)

        # Save report
        with open(os.path.join(output_dir, f"report_{i}.txt"), 'w') as f:
            f.write(f"Fatty Liver Analysis - {filename}\n")
            f.write(f"{'='*50}\n\n")
            if training_accuracy is not None:
                f.write(f"U-Net Model Training Accuracy: {training_accuracy:.2f}%\n")
                f.write(f"U-Net Model Validation Accuracy: {validation_accuracy:.2f}%\n\n")
            f.write(report_text)

        print(f"\nProcessed image {i+1}/{len(X)}: {filename}")
        print(f"Segmentation Accuracy: {metrics['overall_accuracy']:.1f}%")
        print(f"Results saved to {output_dir}")

        # Limit display to avoid clutter
        if i >= 4 and len(X) > 5:
            print(f"\n... and {len(X) - 5} more images processed but not displayed.")
            break

    # Calculate and display overall statistics
    print(f"\n{'='*60}")
    print("OVERALL DATASET STATISTICS")
    print(f"{'='*60}")
    print(f"Total images processed: {len(X)}")
    
    avg_accuracy = np.mean([m['overall_accuracy'] for m in all_metrics])
    avg_coverage = np.mean([m['coverage_percentage'] for m in all_metrics])
    avg_regions = np.mean([m['num_regions'] for m in all_metrics])
    
    print(f"Average Segmentation Accuracy: {avg_accuracy:.2f}%")
    print(f"Average Coverage: {avg_coverage:.2f}%")
    print(f"Average Regions per Image: {avg_regions:.1f}")
    
    if training_accuracy is not None:
        print(f"\nU-Net Model Performance:")
        print(f"  Training Accuracy: {training_accuracy:.2f}%")
        print(f"  Validation Accuracy: {validation_accuracy:.2f}%")
    
    print(f"{'='*60}")
    print(f"\nAll results saved to: {output_dir}")
    
    # Save overall statistics
    with open(os.path.join(output_dir, "overall_statistics.txt"), 'w') as f:
        f.write(f"{'='*60}\n")
        f.write("OVERALL DATASET STATISTICS\n")
        f.write(f"{'='*60}\n")
        f.write(f"Total images processed: {len(X)}\n")
        f.write(f"Average Segmentation Accuracy: {avg_accuracy:.2f}%\n")
        f.write(f"Average Coverage: {avg_coverage:.2f}%\n")
        f.write(f"Average Regions per Image: {avg_regions:.1f}\n")
        
        if training_accuracy is not None:
            f.write(f"\nU-Net Model Performance:\n")
            f.write(f"  Training Accuracy: {training_accuracy:.2f}%\n")
            f.write(f"  Validation Accuracy: {validation_accuracy:.2f}%\n")

# Run the main function when script is executed
if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        import traceback
        traceback.print_exc()